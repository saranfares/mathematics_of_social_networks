{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook includes the code for a simple linear regression model\n",
    "\n",
    "# imports\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on  review.json\n"
     ]
    }
   ],
   "source": [
    "MAIN_DIR = \"data/\"\n",
    "\n",
    "users = \"U4INQZOPSUaj8hMjLlZ3KA PKEzKWv_FktMm2mGPjwd0Q d_TBs6J3twMy9GChqUEXkg bLbSNkLggFnqwNNzzq-Ijw cMEtAiW60I5wE_vLfTxoJQ JaqcCU3nxReTW2cBLHounA QJI9OSEn6ujRCtrX06vs1w YMgZqBUAddmFErxLtCfK_w 1O638BDK_fWuxgTVJwff-A kmE8w5Y785eZmodsx0V6Ag tH0uKD-vNwMoEc3Xk3Cbdg UYcmGbelzRa0Q6JqzLoguw 8DEyKVyplnOcSKx39vatbg C2C0GPKvzWWnP57Os9eQ0w DeVGAiOf2mHVUDfxvuhVlQ Ryxj0u0AW3mRsRypdYli2A DK57YibC5ShBmqQl97CKog whINg-cC-FiAv_ATDGMDTg w-w-k-QXosIKQ8HQVwU6IQ n86B7IkbU20AkxlFX_5aew U4INQZOPSUaj8hMjLlZ3KA PKEzKWv_FktMm2mGPjwd0Q bLbSNkLggFnqwNNzzq-Ijw YMgZqBUAddmFErxLtCfK_w kmE8w5Y785eZmodsx0V6Ag 1O638BDK_fWuxgTVJwff-A QJI9OSEn6ujRCtrX06vs1w DeVGAiOf2mHVUDfxvuhVlQ Ryxj0u0AW3mRsRypdYli2A UYcmGbelzRa0Q6JqzLoguw d_TBs6J3twMy9GChqUEXkg EiwxlbR8fb68lMgEXhcWKA C2C0GPKvzWWnP57Os9eQ0w tH0uKD-vNwMoEc3Xk3Cbdg JaqcCU3nxReTW2cBLHounA 8DEyKVyplnOcSKx39vatbg F_5_UNX-wrAFCXuAkBZRDw whINg-cC-FiAv_ATDGMDTg n86B7IkbU20AkxlFX_5aew hkSiQAfl6w3882JJQzRTlQ PKEzKWv_FktMm2mGPjwd0Q bLbSNkLggFnqwNNzzq-Ijw U4INQZOPSUaj8hMjLlZ3KA tH0uKD-vNwMoEc3Xk3Cbdg UYcmGbelzRa0Q6JqzLoguw C2C0GPKvzWWnP57Os9eQ0w n86B7IkbU20AkxlFX_5aew JaqcCU3nxReTW2cBLHounA kmE8w5Y785eZmodsx0V6Ag 8DEyKVyplnOcSKx39vatbg N3oNEwh0qgPqPP3Em6wJXw YMgZqBUAddmFErxLtCfK_w 3nDUQBjKyVor5wV0reJChg eZZyuJDouIg4p-GYB3PV_A qewG3X2O4X6JKskxyyqFwQ y3FcL4bLy0eLlkb0SDPnBQ TdYKJgSgY2GF_YJnwsi5yQ oeAhRa8yFa9jtrhaHnOyxQ 3nIuSCZk5f_2WWYMLN7h3w 8OeTLey-p-WaL9ErNEci1Q PKEzKWv_FktMm2mGPjwd0Q U4INQZOPSUaj8hMjLlZ3KA bLbSNkLggFnqwNNzzq-Ijw UYcmGbelzRa0Q6JqzLoguw tH0uKD-vNwMoEc3Xk3Cbdg kmE8w5Y785eZmodsx0V6Ag C2C0GPKvzWWnP57Os9eQ0w YMgZqBUAddmFErxLtCfK_w n86B7IkbU20AkxlFX_5aew JaqcCU3nxReTW2cBLHounA 8DEyKVyplnOcSKx39vatbg d_TBs6J3twMy9GChqUEXkg 3nDUQBjKyVor5wV0reJChg F_5_UNX-wrAFCXuAkBZRDw eZZyuJDouIg4p-GYB3PV_A N3oNEwh0qgPqPP3Em6wJXw Ryxj0u0AW3mRsRypdYli2A DeVGAiOf2mHVUDfxvuhVlQ QJI9OSEn6ujRCtrX06vs1w qewG3X2O4X6JKskxyyqFwQ\"\n",
    "businesses = \"X4JNXUYY8wbaaDmk3BPzlWw iCQpiavjjPzJ5_3gPD5Ebg K7lWdNUhCbcnEvI0NhGewg RESDUcs7fIiihp38.d6_6g DkYS3arLOhA8si5uUEmHOw X5LNZ67Yw9RD6nf4_UhXOjw P7pxQFqr7yBKMMI2J51udw rcaPajgKOJC2vo_l3xa42A ujHiaprwCQ5ewziu0Vi9rw X2weQS.RnoOBhb1KsHKyoSQ eoHdUeQDNgQ6WYEnP2aiRw El4FC8jcawUVgw_0EIcbaQ Wxxvi3LZbHNIDwJ.ZimtnA cYwJA2A6I12KNkm2rtXd5g Cni2l.VKG_pdospJ6xliXQ f4x1YBxkLrZg652xt2KR5g KskYqH1Bi7Z_61pH6Om8pg eAc9Vd6loOgRQolMXQt6FA NCFwm2.TDb.oBQ2medmYDg pSQFynH1VxkfSmehRXlZWw X4JNXUYY8wbaaDmk3BPzlWw P7pxQFqr7yBKMMI2J51udw DkYS3arLOhA8si5uUEmHOw iCQpiavjjPzJ5_3gPD5Ebg cYwJA2A6I12KNkm2rtXd5g ujHiaprwCQ5ewziu0Vi9rw X5LNZ67Yw9RD6nf4_UhXOjw K7lWdNUhCbcnEvI0NhGewg El4FC8jcawUVgw_0EIcbaQ RESDUcs7fIiihp38.d6_6g eoHdUeQDNgQ6WYEnP2aiRw f4x1YBxkLrZg652xt2KR5g rcaPajgKOJC2vo_l3xa42A Wxxvi3LZbHNIDwJ.ZimtnA X2weQS.RnoOBhb1KsHKyoSQ NCFwm2.TDb.oBQ2medmYDg AV6weBrZFFBfRGCbcRGO4g UUGoM4q4i8rK2CBRS0xDAw KskYqH1Bi7Z_61pH6Om8pg Cni2l.VKG_pdospJ6xliXQ K7lWdNUhCbcnEvI0NhGewg DkYS3arLOhA8si5uUEmHOw X4JNXUYY8wbaaDmk3BPzlWw RESDUcs7fIiihp38.d6_6g iCQpiavjjPzJ5_3gPD5Ebg X5LNZ67Yw9RD6nf4_UhXOjw X2weQS.RnoOBhb1KsHKyoSQ P7pxQFqr7yBKMMI2J51udw eoHdUeQDNgQ6WYEnP2aiRw Wxxvi3LZbHNIDwJ.ZimtnA rcaPajgKOJC2vo_l3xa42A ujHiaprwCQ5ewziu0Vi9rw El4FC8jcawUVgw_0EIcbaQ cYwJA2A6I12KNkm2rtXd5g NvKNe9DnQavC9GstglcBJQ uGupeWqih0yIcCg8anM1PA QJatAcxYgK1Zp9BRZMAx7g KskYqH1Bi7Z_61pH6Om8pg Cni2l.VKG_pdospJ6xliXQ LNGBEEelQx4zbfWnlc66cw X4JNXUYY8wbaaDmk3BPzlWw K7lWdNUhCbcnEvI0NhGewg RESDUcs7fIiihp38.d6_6g DkYS3arLOhA8si5uUEmHOw iCQpiavjjPzJ5_3gPD5Ebg X5LNZ67Yw9RD6nf4_UhXOjw P7pxQFqr7yBKMMI2J51udw X2weQS.RnoOBhb1KsHKyoSQ eoHdUeQDNgQ6WYEnP2aiRw rcaPajgKOJC2vo_l3xa42A Wxxvi3LZbHNIDwJ.ZimtnA ujHiaprwCQ5ewziu0Vi9rw El4FC8jcawUVgw_0EIcbaQ cYwJA2A6I12KNkm2rtXd5g Cni2l.VKG_pdospJ6xliXQ KskYqH1Bi7Z_61pH6Om8pg QJatAcxYgK1Zp9BRZMAx7g LNGBEEelQx4zbfWnlc66cw uGupeWqih0yIcCg8anM1PA NvKNe9DnQavC9GstglcBJQ\"\n",
    "\n",
    "user_set = set()\n",
    "business_set = set()\n",
    "for user in users.split(\" \"):\n",
    "    if user not in user_set:\n",
    "        user_set.add(user)\n",
    "\n",
    "for business in businesses.split(\" \"):\n",
    "    if business not in business_set:\n",
    "        business_set.add(business)\n",
    "\n",
    "#business_file = open(MAIN_DIR+\"business_matrix.txt\", \"w\")\n",
    "\n",
    "data = {}\n",
    "item = \"review\"\n",
    "file = item + \".json\"\n",
    "print(\"working on \", file)\n",
    "\n",
    "# open the input file and read in lines\n",
    "f = open(MAIN_DIR + file , \"r\")\n",
    "lines = f.readlines()\n",
    "\n",
    "# figure out which attributes to keep using the attributes dict\n",
    "for line in lines:\n",
    "    # read in as json\n",
    "    # filter out to get only the attributes we want\n",
    "    l = json.loads(line)\n",
    "    txt = l[\"text\"].replace('\\n', ' ')\n",
    "    label = l[\"stars\"]\n",
    "    if l[\"business_id\"] not in data.keys():\n",
    "        data[l[\"business_id\"]] = {\"text\":[], \"label\":[]}\n",
    "    data[l[\"business_id\"]][\"text\"].append(txt)\n",
    "    data[l[\"business_id\"]][\"label\"].append(label)\n",
    "\n",
    "    if l[\"user_id\"] not in data.keys():\n",
    "        data[l[\"user_id\"]] = {\"text\":[], \"label\":[]}\n",
    "    data[l[\"user_id\"]][\"text\"].append(txt)\n",
    "    data[l[\"user_id\"]][\"label\"].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through reviews and find the ones that go with all of the top restaurants\n",
    "business_revs = {\"text\":[], \"label\":[]}\n",
    "print(data)\n",
    "for business in business_set:\n",
    "    # find all reviews for this business\n",
    "    reviews = {}\n",
    "    if business in data.keys():\n",
    "        reviews = data[business]\n",
    "    for count in range(0,len(reviews[\"text\"])):\n",
    "        txt = reviews[\"text\"][count].replace(\"\\n\", \"\")\n",
    "        lab = reviews[\"label\"][count]\n",
    "        business_revs[\"text\"].append(txt)\n",
    "        business_revs[\"label\"].append(lab)\n",
    "\n",
    "print(\"num reviews business: \", count)\n",
    "# go through reviews and find the ones that go with all of the top users\n",
    "\n",
    "count = 0\n",
    "user_revs = {\"text\":[], \"label\":[]}\n",
    "for user in user_set:\n",
    "    # find all reviews for this user\n",
    "    if user in data.keys():\n",
    "        reviews = data[user]\n",
    "    for count in range(len(reviews[\"text\"])):\n",
    "        txt = reviews[\"text\"][count].replace(\"\\n\", \"\")\n",
    "        lab = reviews[\"label\"][count]\n",
    "        user_revs[\"text\"].append(txt)\n",
    "        user_revs[\"label\"].append(lab)\n",
    "\n",
    "print(\"num reviews user: \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train + test sets\n",
    "split = count//10\n",
    "train = {\"text\":[], \"label\":[]}\n",
    "test = {\"text\":[], \"label\":[]}\n",
    "train[\"text\"] = business_revs[\"text\"][0:split*9]\n",
    "train[\"label\"] = business_revs[\"label\"][0:split*9]\n",
    "\n",
    "test[\"text\"] = business_revs[\"text\"][split*9:split*10]\n",
    "test[\"label\"] = business_revs[\"label\"][split*9:split*10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model on user data\n",
    "# vectorize the text to be able to input it into model\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train[\"text\"])\n",
    "X_test_counts = count_vect.transform(test[\"text\"])\n",
    "print(\"matrix with shape:\", X_train_counts.shape)\n",
    "\n",
    "OUTPUT_FILE = open(\"single_exp_\"+option+\"_error_analysis.txt\", \"w\")\n",
    "\n",
    "# \n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_counts, train[\"label\"])\n",
    "s = clf.score(X_test_counts, test[\"label\"])\n",
    "predictions = clf.predict(X_test_counts)\n",
    "report = classification_report(test[\"label\"], predictions)\n",
    "p, r, f, supp = precision_recall_fscore_support(test[\"label\"], predictions, average='micro')\n",
    "print(\"RESULTS FOR LOGISTIC REGRESSION:\")\n",
    "print(\"REPORT BY CLASS\\n\", report)\n",
    "print(\"score: \", s)\n",
    "print(\"precision: \", p)\n",
    "print(\"recall: \", r)\n",
    "print(\"fbeta: \", f)\n",
    "print(\"support: \", supp)\n",
    "print(\"confusion matrix: \", confusion_matrix(test[\"label\"], predictions))\n",
    "for count in range(len(test[\"label\"])):\n",
    "    if test[\"label\"][count] != predictions[count]:\n",
    "        OUTPUT_FILE.write(\"true label: \" + str(test[\"label\"][count]) + \", predicted label: \" + str(predictions[count]) + \",\"+ \"text: \" + str(test[\"text\"][count].replace(\"\\n\", \" \")) + \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model on restaurant data\n",
    "# vectorize the text to be able to input it into model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
